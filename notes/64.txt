id
64
create
2024-06-25T20:08:51.345130898+08:00
parent
58

另外一个例子就是transformer了。

这其实已经非常接近一个能实现可变计算量的方案了。模型自己决定自己的输出有多长，只要它觉得自己还没算完就不会输出终止记号，它就可以获得更多的计算量去回答更难的问题。

它的局限性是计算量和输出结果的长度绑定在了一起。回答一个更难的问题必须用一个更长的回答，而且前半段常常会是一些无关痛痒的问候语/套话/背景资料（还常常是编的）。并不是因为这个问题的答案本身表达起来更复杂，而是因为它还没有完成足够的计算来得到答案。

前两年有一篇很有意思的工作，说只要用「step by step」来催眠模型，它的能力就会有显著提升。其实就是让它有更充足的计算量来把它所懂得的知识概括成正确的答案。因为每次模型输出下一个符号都是以（最近的一部分）此前生成的符号作为输入，因此模型可以拿输出当草稿纸用，通过输出来把前一步计算得到的中间状态传递给接下来的计算。只不过这个中间状态碰巧也是「step by step」所要求的输出，所以模型就真的这样做了。

如今越来越大的transformer模型已经足以在一步之内「想清楚」很多事情了，而不再依赖于更长的回答所带来的更大的计算量配额。从完成可变计算量任务的角度来说属于是走了回头路。